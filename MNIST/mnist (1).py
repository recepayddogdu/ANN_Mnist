# -*- coding: utf-8 -*-
"""MNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ehfZdkxrlFEjqndbSysiQIK03LGQ-FBB

# **MNIST Dataseti ile Deep Learning Uygulaması**
"""

from keras.datasets import mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()

print("ilk datanin shape'i:", x_train[0].shape) # (28, 28)
print("ilk datanin icerigi:", y_train[0]) # 5

"""Normalization"""

x_train = x_train.reshape((60000, 28*28)) #Goruntuyu vektore donusturur
x_train = x_train.astype('float32') / 255 #Normalize eder
x_test = x_test.reshape((10000, 28*28)) 
x_test = x_test.astype('float32') / 255

print("Normalizasyon sonrasi shape:", x_train.shape) # (60000, 784)

"""Devamında ağın yapısını tanımlamamız gerekiyor."""

from keras import models
from keras import layers

"""`from keras.models import Sequential` gibi de kullanabiliriz.

Modeli kullanmadan önce `models.Sequential()` gibi tanımlamalıyız.
"""

model = models.Sequential()

#Giris katmani
model.add(layers.Dense(16, 
                       activation='relu', 
                       input_shape=(28*28,)))

model.add(layers.Dense(16,
                       activation='relu'))

"""Çıkış katmanımızda 10 adet çıkış olmalı.  
0,1,2,3,4,5,6,7,8,9

Bu, **multi class classification** olarak geçer. Dolayısıyla çıkış katmanımızda activation function olarak **softmax** tercih ediyoruz.

**Binary Classification**'da ise genelde **sigmoid** tercih edilir.
"""

#Cikis katmani
model.add(layers.Dense(10, #cikis sayisina esit olmali
                       activation="softmax"))

"""`categorical_crossentropy` kullanabilmemiz için, çıkış datalarımız olan *y_train* ve *y_test* datalarını categorical'a dönüştürmemiz gerekiyor.

Örneğin, **5** olarak değil **[0,0,0,0,0,1,0,0,0,0]** olarak modele vermemiz gerekiyor.

`sparse_categorical_crossentropy` bu işlemi kendisi yapar. `to_categorical` yapmamıza gerek kalmaz.
"""

from keras.utils import to_categorical
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

y_train.shape

y_train[0,:] # 5 vardi

"""Optimizer olarak *Stochastic Gradient Descent (SGD)* kullanıyoruz.

Loss function olarak *Categorical Cross Entropy* kullanıyoruz.  
Problem tipi Regresyon ise genelde *mse, mae* gibi regresyon fonksiyonları kullanılır.  
Multi class classification'da ise *cross entropy* veya *sparse categorical cross entropy* kullanılır.

Metrics ise ekrana yazdıracağımız değeri belirtir.



"""

model.compile(optimizer="sgd", 
              loss="categorical_crossentropy",
              metrics=["accuracy"])

"""Modelin yapısını özet olarak görelim;"""

model.summary()

"""Birinci katmanın çıkışı 16 olarak gözüküyor.  

Neden 12560 parametre var?  
Girişimiz 784 elemanlı.  
Her bir hücreden 784x16 adet *weights* bağlantısı var demektir.  
*Bias*'lar da var; 16 adet. (her bir hücre için 1 adet.)  
784x16+16 = 12560 parametreye denk gelir.

---

Sıradaki adımımız modeli eğitmek.
"""

model.fit(x_train, y_train, epochs=5, batch_size=64)

"""Eğitilmiş ağın performansını ölçelim.

Eğitim bittikten sonra eğitimde kullanılmamış görüntülerle ağın başarımı belli olur.
"""

test_loss, test_acc = model.evaluate(x_test, y_test) #test_images, test_labels



